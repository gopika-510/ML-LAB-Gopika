# -*- coding: utf-8 -*-
"""emailp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Eevmc5RjNYCf1aYNBf56VvJlDPcgLbbd
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
df=pd.read_csv('/content/drive/MyDrive/spam.csv')
df.head()

"""EDA"""

df.isnull().sum()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

from sklearn.metrics import (
    confusion_matrix, classification_report, roc_auc_score, roc_curve,
    accuracy_score, precision_score, recall_score, f1_score, fbeta_score
)

from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB

# 3. EDA & Handling Missing Values
print("\nMissing Values:\n")
print(df.isnull().sum())
target="class"
# 4. Outlier Detection Function
def detect_outliers(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    return df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]

# 5. Train-Test Split
X = df.drop(columns=target)
y = df[target]

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)

# 6. Train and Evaluate
models = {
    "GaussianNB": GaussianNB(),
    "MultinomialNB": MultinomialNB(),
    "BernoulliNB": BernoulliNB()
}


gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred_gnb = gnb.predict(X_val)

print("\n GaussianNB ")
print("Accuracy:", accuracy_score(y_val, y_pred_gnb))
print("Precision:", precision_score(y_val, y_pred_gnb, average='weighted'))
print("Recall:", recall_score(y_val, y_pred_gnb, average='weighted'))
print("F1 Score:", f1_score(y_val, y_pred_gnb, average='weighted'))
print("F-beta Score (β=0.5):", fbeta_score(y_val, y_pred_gnb, beta=0.5, average='weighted'))

print("\nConfusion Matrix:\n", confusion_matrix(y_val, y_pred_gnb))
print("\nClassification Report:\n", classification_report(y_val, y_pred_gnb))

if hasattr(gnb, "predict_proba"):
    y_proba_gnb = gnb.predict_proba(X_val)[:, 1]
    print("ROC AUC Score:", roc_auc_score(y_val, y_proba_gnb))
    fpr, tpr, _ = roc_curve(y_val, y_proba_gnb)
    plt.plot(fpr, tpr, label="GaussianNB")



mnb = MultinomialNB()
mnb.fit(X_train, y_train)
y_pred_mnb = mnb.predict(X_val)

print("\n MultinomialNB ")
print("Accuracy:", accuracy_score(y_val, y_pred_mnb))
print("Precision:", precision_score(y_val, y_pred_mnb, average='weighted'))
print("Recall:", recall_score(y_val, y_pred_mnb, average='weighted'))
print("F1 Score:", f1_score(y_val, y_pred_mnb, average='weighted'))
print("F-beta Score (β=0.5):", fbeta_score(y_val, y_pred_mnb, beta=0.5, average='weighted'))

print("\nConfusion Matrix:\n", confusion_matrix(y_val, y_pred_mnb))
print("\nClassification Report:\n", classification_report(y_val, y_pred_mnb))

if hasattr(mnb, "predict_proba"):
    y_proba_mnb = mnb.predict_proba(X_val)[:, 1]
    print("ROC AUC Score:", roc_auc_score(y_val, y_proba_mnb))
    fpr, tpr, _ = roc_curve(y_val, y_proba_mnb)
    plt.plot(fpr, tpr, label="MultinomialNB")



bnb = BernoulliNB()
bnb.fit(X_train, y_train)
y_pred_bnb = bnb.predict(X_val)

print("\n BernoulliNB ")
print("Accuracy:", accuracy_score(y_val, y_pred_bnb))
print("Precision:", precision_score(y_val, y_pred_bnb, average='weighted'))
print("Recall:", recall_score(y_val, y_pred_bnb, average='weighted'))
print("F1 Score:", f1_score(y_val, y_pred_bnb, average='weighted'))
print("F-beta Score (β=0.5):", fbeta_score(y_val, y_pred_bnb, beta=0.5, average='weighted'))

print("\nConfusion Matrix:\n", confusion_matrix(y_val, y_pred_bnb))
print("\nClassification Report:\n", classification_report(y_val, y_pred_bnb))

if hasattr(bnb, "predict_proba"):
    y_proba_bnb = bnb.predict_proba(X_val)[:, 1]
    print("ROC AUC Score:", roc_auc_score(y_val, y_proba_bnb))
    fpr, tpr, _ = roc_curve(y_val, y_proba_bnb)
    plt.plot(fpr, tpr, label="BernoulliNB")


plt.title("ROC Curves")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

from sklearn.model_selection import KFold

# Set up 5-Fold cross-validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Function to perform K-Fold CV and print fold-wise accuracy
def evaluate_with_kfold(model, model_name, X, y):
    print(f"\nK-Fold Cross-Validation for {model_name}")
    fold_accuracies = []

    for fold, (train_index, val_index) in enumerate(kf.split(X), 1):
        X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]
        y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]

        model.fit(X_train_fold, y_train_fold)
        y_pred = model.predict(X_val_fold)
        acc = accuracy_score(y_val_fold, y_pred)
        fold_accuracies.append(acc)
        print(f"Fold {fold} Accuracy: {acc:.4f}")

    avg_acc = np.mean(fold_accuracies)
    print(f"Average Accuracy over 5 folds: {avg_acc:.4f}")

# Run for each Naive Bayes model
evaluate_with_kfold(GaussianNB(), "GaussianNB", X, y)
evaluate_with_kfold(MultinomialNB(), "MultinomialNB", X, y)
evaluate_with_kfold(BernoulliNB(), "BernoulliNB", X, y)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import time


X = df.drop(columns="class")
y = df["class"]

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)


print("\n KDTree Algorithm (k=5)")
knn_kdtree = Pipeline([
    ("scaler", StandardScaler()),
    ("knn", KNeighborsClassifier(n_neighbors=5, algorithm="kd_tree"))
])
start_time = time.time()
knn_kdtree.fit(X_train, y_train)
training_time=time.time()-start_time
y_pred = knn_kdtree.predict(X_val)

print(f"Training Time: {training_time:.4f} seconds")
print("Accuracy:", accuracy_score(y_val, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_val, y_pred))
print("Classification Report:\n", classification_report(y_val, y_pred))



print("\n BallTree Algorithm (k=5)")
knn_balltree = Pipeline([
    ("scaler", StandardScaler()),
    ("knn", KNeighborsClassifier(n_neighbors=5, algorithm="ball_tree"))
])
start_time = time.time()
knn_balltree.fit(X_train, y_train)
training_time = time.time() - start_time
y_pred = knn_balltree.predict(X_val)

print(f"Training Time: {training_time:.4f} seconds")
print("Accuracy:", accuracy_score(y_val, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_val, y_pred))
print("Classification Report:\n", classification_report(y_val, y_pred))



print("\n (Varying K)")
for k in [1, 3, 5, 7]:
    knn_auto = Pipeline([
        ("scaler", StandardScaler()),
        ("knn", KNeighborsClassifier(n_neighbors=k, algorithm="auto"))
    ])
    knn_auto.fit(X_train, y_train)
    y_pred = knn_auto.predict(X_val)

    print(f"\n K = {k} ")
    print("Accuracy:", accuracy_score(y_val, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_val, y_pred))
    print("Classification Report:\n", classification_report(y_val, y_pred))

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np
import time

# Split features and labels
X = df.drop(columns="class")
y = df["class"]
classes = np.unique(y)
y_bin = label_binarize(y, classes=classes)
n_classes = y_bin.shape[1] if y_bin.ndim > 1 else 1

# Train-Validation-Test split
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)
y_val_bin = label_binarize(y_val, classes=classes)


# ROC Plotting Function
def plot_roc_curves(y_true_bin, y_proba, title):
    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_proba[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    plt.figure()
    for i in range(n_classes):
        plt.plot(fpr[i], tpr[i], label=f'Class {classes[i]} (AUC = {roc_auc[i]:.2f})')

    plt.plot([0, 1], [0, 1], 'k--', lw=1)
    plt.title(title)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc="lower right")
    plt.grid()
    plt.show()


# --- KDTree ---
print("\n KDTree Algorithm (k=5)")
knn_kdtree = Pipeline([
    ("scaler", StandardScaler()),
    ("knn", KNeighborsClassifier(n_neighbors=5, algorithm="kd_tree"))
])
start_time = time.time()
knn_kdtree.fit(X_train, y_train)
training_time = time.time() - start_time
y_pred = knn_kdtree.predict(X_val)
y_proba = knn_kdtree.predict_proba(X_val)

print(f"Training Time: {training_time:.4f} seconds")
print("Accuracy:", accuracy_score(y_val, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_val, y_pred))
print("Classification Report:\n", classification_report(y_val, y_pred))

plot_roc_curves(y_val_bin, y_proba, "ROC Curve - KDTree (k=5)")


# --- BallTree ---
print("\n BallTree Algorithm (k=5)")
knn_balltree = Pipeline([
    ("scaler", StandardScaler()),
    ("knn", KNeighborsClassifier(n_neighbors=5, algorithm="ball_tree"))
])
start_time = time.time()
knn_balltree.fit(X_train, y_train)
training_time = time.time() - start_time
y_pred = knn_balltree.predict(X_val)
y_proba = knn_balltree.predict_proba(X_val)

print(f"Training Time: {training_time:.4f} seconds")
print("Accuracy:", accuracy_score(y_val, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_val, y_pred))
print("Classification Report:\n", classification_report(y_val, y_pred))

plot_roc_curves(y_val_bin, y_proba, "ROC Curve - BallTree (k=5)")


# --- Varying k ---
print("\n (Varying K)")
for k in [3, 5, 7, 9]:
    knn_auto = Pipeline([
        ("scaler", StandardScaler()),
        ("knn", KNeighborsClassifier(n_neighbors=k, algorithm="auto"))
    ])
    knn_auto.fit(X_train, y_train)
    y_pred = knn_auto.predict(X_val)
    y_proba = knn_auto.predict_proba(X_val)

    print(f"\n K = {k} ")
    print("Accuracy:", accuracy_score(y_val, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_val, y_pred))
    print("Classification Report:\n", classification_report(y_val, y_pred))

    plot_roc_curves(y_val_bin, y_proba, f"ROC Curve - Auto Algorithm (k={k})")

from sklearn.model_selection import cross_val_score, KFold

print("\nK-Fold Cross Validation (k=5) for KNN with Auto Algorithm (k=5)")

# Create pipeline
knn_cv_pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("knn", KNeighborsClassifier(n_neighbors=5, algorithm="auto"))
])

# Define KFold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# Accuracy across folds
cv_scores = cross_val_score(knn_cv_pipeline, X, y, cv=kfold, scoring='accuracy')

# Output
print("Cross-Validation Accuracies:", cv_scores)
print("Mean Accuracy: {:.4f}".format(np.mean(cv_scores)))
print("Standard Deviation: {:.4f}".format(np.std(cv_scores)))

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
from sklearn.model_selection import train_test_split, cross_val_score, KFold
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import time
X = df.drop(columns="class")
y = df["class"]
classes = y.unique()
y_bin = label_binarize(y, classes=classes)
n_classes = y_bin.shape[1] if y_bin.ndim > 1 else 1
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)

# Kernels to try
kernels = ['linear', 'poly', 'rbf', 'sigmoid']

for kernel in kernels:
    print(f"\nSVM with {kernel} kernel")
    svm_pipeline = Pipeline([
        ("scaler", StandardScaler()),
        ("svm", SVC(kernel=kernel, probability=True))  # probability=True needed for ROC
    ])

    start_time = time.time()
    svm_pipeline.fit(X_train, y_train)
    training_time = time.time() - start_time

    y_pred = svm_pipeline.predict(X_val)
    y_proba = svm_pipeline.predict_proba(X_val)

    print(f"Training Time: {training_time:.4f} seconds")
    print("Accuracy:", accuracy_score(y_val, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_val, y_pred))
    print("Classification Report:\n", classification_report(y_val, y_pred))
    y_val_bin = label_binarize(y_val, classes=classes)
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_proba[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    plt.figure()
    for i in range(n_classes):
        plt.plot(fpr[i], tpr[i], label=f'Class {classes[i]} (AUC = {roc_auc[i]:.2f})')
    plt.plot([0, 1], [0, 1], 'k--', lw=1)
    plt.title(f"ROC Curve - SVM ({kernel} kernel)")
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc="lower right")
    plt.grid()
    plt.show()

# K-Fold Cross Validation (k=5)
print("\nK-Fold Cross Validation (k=5) using Linear Kernel")
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
svm_cv_pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", SVC(kernel='linear'))
])
cv_scores = cross_val_score(svm_cv_pipeline, X, y, cv=kfold, scoring='accuracy')
print("Cross-Validation Accuracies:", cv_scores)
print("Mean CV Accuracy: {:.4f}".format(np.mean(cv_scores)))

# ===============================
# 1. Imports
# ===============================
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import time

from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.pipeline import Pipeline

from sklearn.metrics import (
    confusion_matrix, classification_report, roc_auc_score, roc_curve,
    accuracy_score, precision_score, recall_score, f1_score, fbeta_score, auc
)

from sklearn.svm import SVC

# ===============================
# 2. Data Overview
# ===============================
print("\nMissing Values:\n")
print(df.isnull().sum())

target = "class"

# ===============================
# 3. Outlier Detection Function
# ===============================
def detect_outliers(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    return df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]

# ===============================
# 4. Train-Test Split
# ===============================
X = df.drop(columns=target)
y = df[target]
classes = y.unique()

# One-vs-rest binarization for ROC
y_bin = label_binarize(y, classes=classes)
n_classes = y_bin.shape[1] if y_bin.ndim > 1 else 1

X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)

# ===============================
# 5. SVM Models with Different Kernels
# ===============================
kernels = ['linear', 'poly', 'rbf', 'sigmoid']

for kernel in kernels:
    print(f"\n===== SVM with {kernel} kernel =====")
    svm_pipeline = Pipeline([
        ("scaler", StandardScaler()),
        ("svm", SVC(kernel=kernel, probability=True))
    ])

    start_time = time.time()
    svm_pipeline.fit(X_train, y_train)
    training_time = time.time() - start_time

    y_pred = svm_pipeline.predict(X_val)
    y_proba = svm_pipeline.predict_proba(X_val)

    print(f"Training Time: {training_time:.4f} seconds")
    print("Accuracy:", accuracy_score(y_val, y_pred))
    print("Precision:", precision_score(y_val, y_pred, average='weighted'))
    print("Recall:", recall_score(y_val, y_pred, average='weighted'))
    print("F1 Score:", f1_score(y_val, y_pred, average='weighted'))
    print("F-beta Score (β=0.5):", fbeta_score(y_val, y_pred, beta=0.5, average='weighted'))

    print("\nConfusion Matrix:\n", confusion_matrix(y_val, y_pred))
    print("\nClassification Report:\n", classification_report(y_val, y_pred))

    # ROC for each class
    y_val_bin = label_binarize(y_val, classes=classes)
    fpr, tpr, roc_auc = {}, {}, {}
    plt.figure()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_proba[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])
        plt.plot(fpr[i], tpr[i], label=f'Class {classes[i]} (AUC = {roc_auc[i]:.2f})')

    plt.plot([0, 1], [0, 1], 'k--', lw=1)
    plt.title(f"ROC Curve - SVM ({kernel} kernel)")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.legend(loc="lower right")
    plt.grid()
    plt.show()

# ===============================
# 6. K-Fold Cross Validation
# ===============================
print("\n===== K-Fold Cross Validation (k=5) - Linear Kernel =====")
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
svm_cv_pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", SVC(kernel='linear'))
])
cv_scores = cross_val_score(svm_cv_pipeline, X, y, cv=kfold, scoring='accuracy')
print("Cross-Validation Accuracies:", cv_scores)
print("Mean CV Accuracy: {:.4f}".format(np.mean(cv_scores)))

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import loguniform, randint

# Base pipeline
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", SVC(probability=True))
])

# Parameter spaces for each kernel
param_spaces = {
    "linear":  {"svm__kernel": ["linear"],  "svm__C": loguniform(1e-3, 1e3)},
    "poly":    {"svm__kernel": ["poly"],    "svm__C": loguniform(1e-3, 1e3),
                "svm__degree": randint(2, 6), "svm__gamma": loguniform(1e-4, 1e1)},
    "rbf":     {"svm__kernel": ["rbf"],     "svm__C": loguniform(1e-3, 1e3),
                "svm__gamma": loguniform(1e-4, 1e1)},
    "sigmoid": {"svm__kernel": ["sigmoid"], "svm__C": loguniform(1e-3, 1e3),
                "svm__gamma": loguniform(1e-4, 1e1)}
}

best_params = {}
for kernel, params in param_spaces.items():
    print(f"\n=== {kernel.upper()} Kernel ===")
    search = RandomizedSearchCV(
        pipeline, param_distributions=params,
        n_iter=10, cv=3, scoring='accuracy',
        n_jobs=-1, random_state=42
    )
    search.fit(X_train, y_train)
    best_params[kernel] = search.best_params_
    print("Best Params:", search.best_params_)
    print("Best CV Accuracy:", search.best_score_)

    # Validation
    y_pred = search.best_estimator_.predict(X_val)
    print("Validation Accuracy:", accuracy_score(y_val, y_pred))
    print("Classification Report:\n", classification_report(y_val, y_pred))

print("\nSummary of Best Parameters:", best_params)

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report
import numpy as np

# Pipeline
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", SVC(probability=True))
])

# Grid parameters
param_grid = [
    {"svm__kernel": ["linear"], "svm__C": np.logspace(-3, 3, 5)},
    {"svm__kernel": ["poly"], "svm__C": np.logspace(-3, 3, 5),
     "svm__degree": [2, 3, 4], "svm__gamma": ["scale", "auto"]},
    {"svm__kernel": ["rbf"], "svm__C": np.logspace(-3, 3, 5),
     "svm__gamma": ["scale", "auto"]},
    {"svm__kernel": ["sigmoid"], "svm__C": np.logspace(-3, 3, 5),
     "svm__gamma": ["scale", "auto"]}
]

# Grid search
grid = GridSearchCV(pipeline, param_grid, cv=3, scoring="accuracy", n_jobs=-1)
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)
print("Best CV Accuracy:", grid.best_score_)

# Validation
y_pred = grid.best_estimator_.predict(X_val)
print("Validation Accuracy:", accuracy_score(y_val, y_pred))
print("Classification Report:\n", classification_report(y_val, y_pred))