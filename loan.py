# -*- coding: utf-8 -*-
"""loan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ioBuXM4x0gUo8MU41Qbdn-yu73jfFe1R
"""

from google.colab import drive
drive.mount('/content/drive')



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler,OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score

print("Dataset size after preprocessing:", df.shape[0])

df=pd.read_csv('/content/drive/MyDrive/loan.csv')
df.head()
df.isnull().sum()

target = 'Loan Sanction Amount (USD)'

categorical_features=df.select_dtypes(include=['object']).columns.tolist()
numerical_features=df.select_dtypes(include=['int64','float64']).columns.tolist()
numerical_features=[col for col in numerical_features if target!=col]

numeric_pipeline=Pipeline([
    ('imputer',SimpleImputer(strategy='mean')),
    ('scaler',StandardScaler())
])

categorical_pipeline=Pipeline([
    ('imputer',SimpleImputer(strategy='most_frequent')),
    ('onehot',OneHotEncoder(drop='first',handle_unknown='ignore'))
])

preprocessor=ColumnTransformer([
    ('num',numeric_pipeline,numerical_features),
    ('cat',categorical_pipeline,categorical_features)
])

# Drop rows where the target value is missing
df = df.dropna(subset=['Loan Sanction Amount (USD)'])

X=df.drop(columns=target)
y=df[target]

X_train,X_temp,y_train,y_temp=train_test_split(X,y,random_state=42,test_size=0.3)
X_test,X_val,y_test,y_val=train_test_split(X,y,random_state=42,test_size=0.5)
model=Pipeline([
    ('preprocessor',preprocessor),
    ('regressor',LinearRegression())

])

model.fit(X_train,y_train)
y_test_pred=model.predict(X_test)
y_val_pred=model.predict(X_val)

def evaluate(y_true,y_pred):
  print('MSE',mean_squared_error(y_true,y_pred))
  print('MAE',mean_absolute_error(y_true,y_pred))
  print('r2',r2_score(y_true,y_pred))

print('test')
evaluate(y_test, y_test_pred)
print('validation')
evaluate(y_val, y_val_pred)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

def evaluate(y_true, y_pred, X_data):
    n = len(y_true)                    # number of samples
    k = X_data.shape[1]               # number of features (after encoding)

    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)

    # Adjusted R² formula
    adjusted_r2 = 1 - ((1 - r2) * (n - 1)) / (n - k - 1)

    print(f"MAE : {mae:.2f}")
    print(f"MSE : {mse:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"R²  : {r2:.4f}")
    print(f"Adjusted R²: {adjusted_r2:.4f}")

print("Test Set Evaluation:")
evaluate(y_test, y_test_pred, X_test)

print("\nValidation Set Evaluation:")
evaluate(y_val, y_val_pred, X_val)

print("Dataset size after preprocessing:", df.shape[0])

plt.figure(figsize=(6,4))
sns.histplot(df[target], kde=True, bins=30)
plt.title('Distribution of Loan Amount')
plt.show()
# Correlation Heatmap
numeric_df = df.select_dtypes(include=['number'])
# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()
# Actual vs Predicted
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_test_pred, alpha=0.6, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Actual Loan Amount')
plt.ylabel('Predicted Loan Amount')
plt.title('Actual vs Predicted')
plt.show()
# Residual Plot
residuals = y_test - y_test_pred
plt.figure(figsize=(6,4))
sns.histplot(residuals, kde=True)
plt.title('Residuals Distribution')
plt.show()
# Boxplots of numerical features
for col in numerical_features:
    plt.figure(figsize=(5,3))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

# Feature Importance
model_coeff = model.named_steps['regressor'].coef_
feature_names = model.named_steps['preprocessor'].get_feature_names_out()

coef_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': model_coeff
}).sort_values(by='Coefficient', key=abs, ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(data=coef_df, x='Coefficient', y='Feature')
plt.title('Feature Coefficients (Importance)')
plt.show()

from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd

# 1. Remove any rows with NaNs in target
df_clean = df.dropna(subset=['Loan Sanction Amount (USD)'])

# 2. Define target and features
X = df_clean.drop(['Loan Sanction Amount (USD)'], axis=1)
y = df_clean['Loan Sanction Amount (USD)']

# Ensure y is numeric and has no NaNs
y = pd.to_numeric(y, errors='coerce')
X = X.reset_index(drop=True)
y = y.reset_index(drop=True)

# 3. Apply KFold CV
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Store metrics
mae_list = []
mse_list = []
rmse_list = []
r2_list = []

fold = 1
results = []

for train_index, test_index in kf.split(X):
    X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]
    y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]

    # Create and train pipeline
    model = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', LinearRegression())
    ])

    model.fit(X_train_cv, y_train_cv)
    y_pred_cv = model.predict(X_test_cv)

    # Compute metrics
    mae = mean_absolute_error(y_test_cv, y_pred_cv)
    mse = mean_squared_error(y_test_cv, y_pred_cv)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test_cv, y_pred_cv)

    # Save to lists
    mae_list.append(mae)
    mse_list.append(mse)
    rmse_list.append(rmse)
    r2_list.append(r2)

    results.append([f"Fold {fold}", round(mae, 2), round(mse, 2), round(rmse, 2), round(r2, 2)])
    fold += 1

# 4. Compute averages
results.append(["Average",
                round(np.mean(mae_list), 2),
                round(np.mean(mse_list), 2),
                round(np.mean(rmse_list), 2),
                round(np.mean(r2_list), 2)])

# 5. Display as table
results_df = pd.DataFrame(results, columns=["Fold", "MAE", "MSE", "RMSE", "R2 Score"])
print("\nCross-Validation Results Table:")
print(results_df)